// Manual evaluation test to see if we can trigger evals for Mastra Cloud
import { mastra } from './src/mastra/index.js';
import { evaluate } from '@mastra/evals';
import { AnswerRelevancyMetric } from '@mastra/evals/llm';
import { google } from '@ai-sdk/google';

async function testManualEvaluation() {
  console.log('ğŸ§ª Testing Manual Evaluation for Mastra Cloud...\n');
  
  try {
    // Get the agent
    const agent = mastra.getAgent('tomorrowTravelAgent');
    
    // Test query
    const testQuery = "I want to visit a warm beach destination in December with a $2000 budget. What do you recommend?";
    
    console.log('ğŸ“ Query:', testQuery);
    
    // Generate response
    const response = await agent.generate([
      {
        role: 'user',
        content: testQuery
      }
    ]);
    
    console.log('\nğŸ¤– Agent Response:');
    console.log(response.text);
    
    // Create evaluation metric
    const evalModel = google(process.env.MODEL ?? "gemini-2.5-pro");
    const answerRelevancyMetric = new AnswerRelevancyMetric(evalModel, { scale: 1 });
    
    // Run manual evaluation
    console.log('\nğŸ” Running manual evaluation...');
    const evalResult = await evaluate(testQuery, response.text, answerRelevancyMetric);
    
    console.log('\nğŸ“Š Evaluation Result:');
    console.log('Score:', evalResult.score);
    console.log('Info:', evalResult.info);
    
    console.log('\nâœ… Manual evaluation completed!');
    console.log('ğŸ’¡ Check Mastra Cloud dashboard to see if this evaluation appears.');
    
  } catch (error) {
    console.error('âŒ Error:', error.message);
  }
}

testManualEvaluation();
